{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1EQ5G9rQcwE"
   },
   "source": [
    "# Clustering and PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Toc_OzXYQcwH"
   },
   "source": [
    "### Mushroom Dataset\n",
    "\n",
    "Podeis obtener el conjunto de datos en el siguiente enlace:\n",
    "\n",
    "[Mushroom Dataset](https://www.kaggle.com/uciml/mushroom-classification)\n",
    "\n",
    "Como podréis comprobar, hay muchas variables, todas ellas categóricas, por lo que exploraciones con scatterplot no nos serán útiles como en otros casos.\n",
    "\n",
    "La variable a predecir ``class`` es binaria.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJc845c11KbK"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RWIOS2y_QcwH"
   },
   "outputs": [],
   "source": [
    "# Carga de librerías, las que hemos considerado básicas, añadid lo que queráis :)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KbJPDrpQcwI"
   },
   "source": [
    "### Leer conjunto de datos y primer vistazo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zFJoAIsVQcwI"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL del dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\"\n",
    "\n",
    "# Nombres de las columnas según la documentación oficial\n",
    "column_names = [\n",
    "    \"class\", \"cap-shape\", \"cap-surface\", \"cap-color\", \"bruises\", \"odor\",\n",
    "    \"gill-attachment\", \"gill-spacing\", \"gill-size\", \"gill-color\", \"stalk-shape\",\n",
    "    \"stalk-root\", \"stalk-surface-above-ring\", \"stalk-surface-below-ring\",\n",
    "    \"stalk-color-above-ring\", \"stalk-color-below-ring\", \"veil-type\", \"veil-color\",\n",
    "    \"ring-number\", \"ring-type\", \"spore-print-color\", \"population\", \"habitat\"\n",
    "]\n",
    "\n",
    "# Leer el dataset desde la URL, sin cabeceras, usando los nombres definidos\n",
    "df = pd.read_csv(url, header=None, names=column_names)\n",
    "\n",
    "# Mostrar las primeras 5 filas del dataframe\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga del dataset\n",
    "\n",
    "Comenzamos leyendo el dataset de setas directamente desde la fuente oficial de la UCI.  \n",
    "Este archivo no incluye nombres de columna, por lo que se los añadimos manualmente según la documentación del dataset.\n",
    "\n",
    "Cada fila representa un hongo, y cada columna describe una característica (forma, color, olor, etc.).\n",
    "\n",
    "La columna `class` indica si el hongo es comestible (`e`) o venenoso (`p`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dePM9qXKQcwJ"
   },
   "source": [
    "### Exploración de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45TsUuwkQcwJ"
   },
   "outputs": [],
   "source": [
    "# Mostrar información general del DataFrame\n",
    "df.info()\n",
    "\n",
    "# Mostrar número de filas, columnas y valores únicos por variable\n",
    "print(f\"\\nNúmero de filas: {df.shape[0]}\")\n",
    "print(f\"Número de columnas: {df.shape[1]}\")\n",
    "print(\"\\nValores únicos por variable:\")\n",
    "print(df.nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripción del conjunto de datos\n",
    "\n",
    "En este bloque obtenemos una visión general del dataset:\n",
    "\n",
    "- `df.info()` nos muestra cuántos valores hay por columna y el tipo de datos.\n",
    "- `df.shape` nos indica el número de instancias (filas) y variables (columnas).\n",
    "- `df.nunique()` nos dice cuántos valores diferentes hay en cada variable, lo cual nos ayuda a entender la variedad en los datos.\n",
    "\n",
    "Dado que todas las variables son categóricas, es normal que el tipo de dato sea `object`.\n",
    "Este análisis nos ayuda a detectar posibles columnas poco informativas (con un solo valor) o con demasiados valores únicos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Md7i8gXBQcwJ"
   },
   "source": [
    "#### Calcular el número de nulos de cada feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8xXz4mT0QcwJ"
   },
   "outputs": [],
   "source": [
    "# Contar valores nulos estándar (NaN)\n",
    "print(\"Valores nulos por columna:\\n\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Contar valores que en realidad son '?' (suelen aparecer como texto en datasets antiguos)\n",
    "print(\"\\nValores '?' por columna (posibles nulos codificados):\\n\")\n",
    "print((df == '?').sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Búsqueda de valores nulos\n",
    "\n",
    "Primero buscamos valores nulos reales (`NaN`) con `df.isnull().sum()`.\n",
    "\n",
    "Sin embargo, en muchos datasets antiguos como este, los valores faltantes están representados como símbolos como `'?'`.\n",
    "\n",
    "Por eso también contamos cuántos `'?'` hay por columna. Esto nos permitirá decidir si imputar, eliminar o transformar esos datos en el preprocesamiento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJv-ez3WQcwK"
   },
   "source": [
    "#### Buscar valores extraños. Para ello, ver los valores únicos en cada feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fUZ2EHmTQcwK"
   },
   "outputs": [],
   "source": [
    "# Crear un nuevo DataFrame con el número de valores únicos por columna\n",
    "features_summary = pd.DataFrame({\n",
    "    \"features\": df.columns,\n",
    "    \"n_values\": df.nunique().values\n",
    "})\n",
    "\n",
    "# Mostrar el resumen\n",
    "features_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores únicos por variable\n",
    "\n",
    "Este resumen nos permite identificar de forma clara cuántos valores diferentes tiene cada variable.\n",
    "\n",
    "Esto nos ayuda a detectar:\n",
    "\n",
    "- Variables con un solo valor (poco informativas, probablemente eliminables)\n",
    "- Variables con muchos valores distintos (pueden requerir codificación especial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXIyz_tdQcwK"
   },
   "source": [
    "#### Tratar aquellos valores que entendamos que sean nulos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OVQnxK1gQcwK"
   },
   "outputs": [],
   "source": [
    "# Reemplazar los '?' de la columna 'stalk-root' con la moda\n",
    "modo = df['stalk-root'].mode()[0]\n",
    "df['stalk-root'] = df['stalk-root'].replace('?', modo)\n",
    "\n",
    "# Verificar que ya no hay '?'\n",
    "(df == '?').sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputación de valores faltantes\n",
    "\n",
    "La columna `stalk-root` contiene valores faltantes representados como `'?'`.\n",
    "\n",
    "Hemos decidido **imputarlos con la moda** (el valor más frecuente de la columna), ya que esto:\n",
    "\n",
    "- Evita perder datos\n",
    "- Evita tratar `'?'` como si fuera una categoría real\n",
    "- Mantiene la consistencia para técnicas como PCA y KMeans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dbmx1Z7QcwK"
   },
   "source": [
    "#### Mirad cuántos valores hay en cada feature, ¿Todas las features aportan información? Si alguna no aporta información, eliminadla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ts2xeUavQcwK"
   },
   "outputs": [],
   "source": [
    "# Identificar columnas con un solo valor único\n",
    "columnas_constantes = features_summary[features_summary[\"n_values\"] == 1][\"features\"].tolist()\n",
    "print(\"Columnas que se eliminarán por tener un solo valor:\")\n",
    "print(columnas_constantes)\n",
    "\n",
    "# Eliminar del DataFrame original\n",
    "df.drop(columns=columnas_constantes, inplace=True)\n",
    "\n",
    "# Verificar dimensiones\n",
    "print(f\"\\nNueva forma del DataFrame: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminación de variables poco informativas\n",
    "\n",
    "Eliminamos las columnas que tienen **un solo valor único**, ya que no aportan variabilidad al modelo.\n",
    "\n",
    "Estas columnas no ayudan a diferenciar entre clases ni influyen en los componentes principales o en la agrupación de datos.\n",
    "\n",
    "En nuestro caso, la columna `veil-type` tiene un único valor y por tanto se elimina.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dX1LM1VQcwK"
   },
   "source": [
    "#### Separar entre variables predictoras y variables a predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "pS9HEA2eQcwK",
    "outputId": "3bc8f166-5b22-41e7-aa6b-69bad0b06280"
   },
   "outputs": [],
   "source": [
    "# Variable objetivo\n",
    "y = df[\"class\"]\n",
    "\n",
    "# Variables predictoras\n",
    "X = df.drop(columns=[\"class\"])\n",
    "\n",
    "# Comprobamos formas\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación de variables predictoras y objetivo\n",
    "\n",
    "Separamos la variable que queremos predecir (`class`) del resto de variables.\n",
    "\n",
    "- `y` contiene la columna `class`, que indica si un hongo es comestible (`e`) o venenoso (`p`).\n",
    "- `X` contiene todas las demás columnas, que usaremos como variables explicativas.\n",
    "\n",
    "Este paso es fundamental para entrenar modelos supervisados o para evaluar cómo se estructuran los datos sin usar la etiqueta.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sN1fZZfZQcwL"
   },
   "source": [
    "#### Codificar correctamente las variables categóricas a numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-4l92dfEQcwL"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Inicializamos el codificador\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Aplicamos OneHotEncoder a X\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "# Convertimos a DataFrame para mayor claridad\n",
    "X_encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(X.columns))\n",
    "\n",
    "# Mostramos las primeras filas del nuevo DataFrame codificado\n",
    "X_encoded_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificación de variables categóricas\n",
    "\n",
    "Usamos `OneHotEncoder` para transformar todas las variables categóricas en variables numéricas.\n",
    "\n",
    "Este proceso convierte cada categoría en una nueva columna binaria (0 o 1), eliminando ambigüedad y permitiendo que algoritmos como PCA y KMeans trabajen correctamente.\n",
    "\n",
    "Por ejemplo:  \n",
    "Una columna con tres valores posibles (`rojo`, `verde`, `azul`) se convierte en tres columnas:\n",
    "- `color_rojo`, `color_verde`, `color_azul`\n",
    "\n",
    "Este paso aumenta la dimensionalidad, pero es necesario para aplicar técnicas matemáticas a datos categóricos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBBAM0bzQcwL"
   },
   "source": [
    "#### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hHxqeJQqQcwL"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# División del dataset (usamos X e y originales antes de codificar si el modelo requiere categorías)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Comprobamos formas\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División en entrenamiento y test\n",
    "\n",
    "Dividimos el conjunto de datos en:\n",
    "\n",
    "- `X_train` / `y_train`: para entrenar modelos\n",
    "- `X_test` / `y_test`: para evaluar su rendimiento\n",
    "\n",
    "Reservamos un **33% para test**, usando `random_state=42` para asegurar que todos obtengamos la misma división.\n",
    "\n",
    "Esto es fundamental cuando comparamos modelos supervisados como Random Forest más adelante.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Por qué hacemos un Train/Test Split?\n",
    "\n",
    "En este paso separamos nuestros datos en dos subconjuntos:\n",
    "\n",
    "- `X_train`, `y_train`: se usan para entrenar los modelos.\n",
    "- `X_test`, `y_test`: se usan para evaluar cómo se comporta el modelo con datos que **no ha visto** antes.\n",
    "\n",
    "Esto nos permite medir la capacidad del modelo para generalizar a nuevos datos.\n",
    "\n",
    "---\n",
    "\n",
    "### ¿Qué estamos dividiendo?\n",
    "\n",
    "- `X`: todas las variables predictoras (características del hongo)\n",
    "- `y`: la clase que indica si el hongo es comestible (`e`) o venenoso (`p`)\n",
    "\n",
    "---\n",
    "\n",
    "### ¿Por qué es importante?\n",
    "\n",
    "Esta división simula un escenario del mundo real:\n",
    "> Entrenas tu modelo con datos históricos y luego lo usas para hacer predicciones sobre nuevos datos que van llegando.\n",
    "\n",
    "Además, **evita el sobreajuste (overfitting)**, es decir, que el modelo se aprenda de memoria los datos del entrenamiento y no sepa generalizar.\n",
    "\n",
    "---\n",
    "\n",
    "### ¿Por qué `random_state=42`?\n",
    "\n",
    "El parámetro `random_state` fija la semilla aleatoria para que la partición sea siempre la misma al ejecutar el código.  \n",
    "Esto permite reproducibilidad: tú y tus compañeros obtendréis el mismo resultado.\n",
    "\n",
    "---\n",
    "\n",
    "### Nota\n",
    "\n",
    "Aunque este paso es fundamental para modelos **supervisados** (como Random Forest),  \n",
    "también nos permite **comparar resultados con modelos no supervisados**, como clustering, en una fase posterior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sL57bzCQcwL"
   },
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhAhJqbKQcwM"
   },
   "source": [
    "Es un conjunto de datos del que aún no hemos visto nada (no tenemos graficas) así que vamos a hacer algunas. Tenemos el problema de que son muchas variables, **PCA al rescate**: le pedimos que nos de dos dimensiones y las pintamos, sabemos que serán **aquellas que retengan más información**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3232KSn9QcwM"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Codificamos X_train con OneHotEncoder para aplicar PCA\n",
    "X_train_encoded = encoder.fit_transform(X_train)\n",
    "\n",
    "# Aplicamos PCA para reducir a 2 dimensiones\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train_encoded)\n",
    "\n",
    "# Creamos un DataFrame para graficar más cómodamente\n",
    "df_pca = pd.DataFrame(data=X_train_pca, columns=[\"PC1\", \"PC2\"])\n",
    "df_pca[\"class\"] = y_train.values\n",
    "\n",
    "# Visualización en scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(\n",
    "    x=\"PC1\", y=\"PC2\", hue=\"class\", palette={\"e\": \"green\", \"p\": \"red\"}, data=df_pca, alpha=0.7\n",
    ")\n",
    "plt.title(\"Visualización del conjunto de entrenamiento con PCA (2 componentes)\")\n",
    "plt.xlabel(\"Primer componente principal (PC1)\")\n",
    "plt.ylabel(\"Segundo componente principal (PC2)\")\n",
    "plt.legend(title=\"Clase\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducción de dimensionalidad con PCA\n",
    "\n",
    "El dataset tiene muchas variables categóricas que, tras ser codificadas con One-Hot Encoding, generan **una matriz de alta dimensión**.\n",
    "\n",
    "Para poder **visualizar los datos en un plano (2D)**, aplicamos PCA (Análisis de Componentes Principales), una técnica que transforma los datos y reduce su dimensionalidad reteniendo la **mayor varianza posible**.\n",
    "\n",
    "En este scatter plot representamos los datos proyectados sobre los **dos primeros componentes principales**, coloreando los puntos según la clase (`comestible` o `venenoso`).\n",
    "\n",
    "Este tipo de visualización nos permite intuir si hay separación o estructura natural entre las clases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMYH_Hv0QcwM"
   },
   "source": [
    "Parece que está bastante separadito, parece que a ojo mucho se puede ver :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QdE0AvlKQcwM"
   },
   "source": [
    "Igualmente, vamos a entrenar un clasificador a ver qué tal lo hace antes de editar más"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eKQqz_EPQcwM"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Codificamos X_train y X_test con OneHotEncoder\n",
    "X_train_encoded = encoder.fit_transform(X_train)\n",
    "X_test_encoded = encoder.transform(X_test)\n",
    "\n",
    "# Entrenamos el modelo\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred = clf.predict(X_test_encoded)\n",
    "\n",
    "# Evaluación del modelo\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nMatriz de confusión:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nReporte de clasificación:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificador supervisado: Random Forest\n",
    "\n",
    "Entrenamos un modelo supervisado con Random Forest para tener un **punto de referencia**.\n",
    "\n",
    "Este modelo intenta aprender la relación entre las características de los hongos (`X_train`) y su clase (`y_train`).\n",
    "\n",
    "Después evaluamos su rendimiento con los datos de test (`X_test`, `y_test`), midiendo:\n",
    "\n",
    "- Precisión (`accuracy`)\n",
    "- Matriz de confusión\n",
    "- Métricas detalladas por clase (`precision`, `recall`, `f1-score`)\n",
    "\n",
    "Este resultado nos sirve como referencia para comparar con métodos no supervisados como KMeans.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PACQlU5_QcwM"
   },
   "source": [
    "Es un conjunto sencillo y Random Forest es muy bueno en su trabajo, Igualmente, vamos a ver qué tamaño tenemos de dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ODibK0D2QcwN"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tamaño del conjunto de entrenamiento\n",
    "\n",
    "El conjunto `X_train` contiene **5443 muestras** y **21 variables predictoras**.\n",
    "\n",
    "Esto significa que:\n",
    "\n",
    "- Estamos entrenando nuestros modelos con 5443 hongos distintos, cada uno descrito por 21 características.\n",
    "- Estas características son variables categóricas como forma, color, superficie del sombrero, olor, etc.\n",
    "- La columna `class` no se incluye aquí porque ya la hemos separado como variable objetivo (`y_train`).\n",
    "\n",
    "Es importante conocer esta forma para:\n",
    "\n",
    "- Evaluar la complejidad del modelo (número de muestras vs número de variables)\n",
    "- Preparar correctamente el preprocesamiento (por ejemplo, One-Hot Encoding aumentará el número de columnas significativamente)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rEVhvRaQcwN"
   },
   "source": [
    "¿Muchas features no? Vamos a reducir las usando PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kEJPZw_cQcwN"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Re-codificamos todo el conjunto para trabajar con variables numéricas\n",
    "X_train_encoded = encoder.fit_transform(X_train)\n",
    "X_test_encoded = encoder.transform(X_test)\n",
    "\n",
    "# Probamos diferentes números de componentes principales\n",
    "n_features = list(range(2, X_train_encoded.shape[1] + 1, 5))  # Ej: [2, 7, 12, ..., 92]\n",
    "scores = []\n",
    "\n",
    "for n in n_features:\n",
    "    # 1. Reducir dimensionalidad con PCA\n",
    "    pca = PCA(n_components=n)\n",
    "    X_train_pca = pca.fit_transform(X_train_encoded)\n",
    "    X_test_pca = pca.transform(X_test_encoded)\n",
    "\n",
    "    # 2. Entrenar clasificador con los datos reducidos\n",
    "    clf = RandomForestClassifier(random_state=42)\n",
    "    clf.fit(X_train_pca, y_train)\n",
    "    y_pred = clf.predict(X_test_pca)\n",
    "\n",
    "    # 3. Guardar la precisión\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    scores.append(score)\n",
    "\n",
    "# Visualizar el rendimiento según el número de componentes\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x=n_features, y=scores, marker=\"o\")\n",
    "plt.title(\"Precisión del clasificador vs. número de componentes PCA\")\n",
    "plt.xlabel(\"Número de componentes\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducción de dimensionalidad con PCA y evaluación supervisada\n",
    "\n",
    "Queremos saber cuántas componentes principales son suficientes para mantener un buen rendimiento del clasificador.\n",
    "\n",
    "Para ello:\n",
    "\n",
    "1. Aplicamos PCA sobre los datos con un número creciente de componentes (`n_features`).\n",
    "2. Entrenamos un modelo de Random Forest sobre esos datos reducidos.\n",
    "3. Medimos su precisión sobre el conjunto de test.\n",
    "\n",
    "Este gráfico nos permite identificar un punto de equilibrio:  \n",
    "el menor número de componentes que mantiene un rendimiento aceptable.\n",
    "\n",
    "Así reducimos la complejidad del modelo sin sacrificar precisión.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de resultados: reducción drástica sin pérdida de precisión\n",
    "\n",
    "Tras aplicar PCA sobre los datos codificados, observamos que con solo **10 componentes principales** el modelo Random Forest alcanza prácticamente la **misma precisión** que con todas las variables.\n",
    "\n",
    "Esto significa que:\n",
    "\n",
    "- Hemos pasado de ~95 columnas (tras OneHotEncoding) a solo 10.\n",
    "- Estamos utilizando aproximadamente un **10% de las variables transformadas**.\n",
    "- Incluso hemos reducido más de la mitad respecto a las **21 variables originales** del dataset sin codificar.\n",
    "\n",
    "Este resultado demuestra que:\n",
    "\n",
    "✔️ Muchas de las variables codificadas eran **redundantes o poco informativas**.  \n",
    "✔️ PCA ha sido muy eficaz para condensar la información en menos dimensiones.  \n",
    "✔️ La reducción de dimensionalidad no solo mejora la eficiencia, sino que **mantiene (o incluso mejora) la capacidad de predicción** del modelo.\n",
    "\n",
    "Este es un gran ejemplo de cómo el preprocesamiento inteligente mejora los modelos sin necesidad de complejidad extra.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Jvqa-leQcwN"
   },
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWiMHKUdQcwN"
   },
   "source": [
    "Viendo que el conjunto de datos es sencillito, podemos intentar hacer algo de clustering a ver qué información podemos obtener.\n",
    "\n",
    "El primer paso va a ser importar la función de Kmeans de sklearn, y a partir de ahi, vamos a buscar el valor óptimo de clusters. Como hemos visto anteriormente, este valor lo obtenemos, por ejemplo, del codo de la gráfica que representa el total de las distancias de los puntos a los centros de los clusters asociados. Os dejo la página de la documentación de sklearn para que lo busquéis:\n",
    "\n",
    "[K-Means on sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)\n",
    "\n",
    "Con esto solo hay que ahora generar los modelos de kmeans, evaluar y pintar la gráfica para los valores de ``k`` que establezcais.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DV0IXFncQcwO"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Aplicamos PCA para reducir a 2 dimensiones antes de hacer clustering\n",
    "# (si no lo has hecho ya en una celda anterior)\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_encoded)\n",
    "\n",
    "# Rango de valores de k (número de clusters a probar)\n",
    "k_values = range(1, 11)\n",
    "scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    # Definir modelo KMeans\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')\n",
    "    kmeans.fit(X_pca)\n",
    "    \n",
    "    # Guardamos la suma de distancias dentro del cluster (inertia)\n",
    "    scores.append(kmeans.inertia_)\n",
    "\n",
    "# Representación del método del codo\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(x=list(k_values), y=scores, marker=\"o\")\n",
    "plt.title(\"Método del codo - Selección del número óptimo de clusters\")\n",
    "plt.xlabel(\"Número de clusters (k)\")\n",
    "plt.ylabel(\"Inercia (suma de distancias a los centroides)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering no supervisado con KMeans\n",
    "\n",
    "Ahora probamos un enfoque **no supervisado**, aplicando `KMeans` sobre los datos reducidos con PCA (2 dimensiones).\n",
    "\n",
    "El objetivo es descubrir si existen agrupaciones naturales en los datos sin usar la clase (`e` o `p`).\n",
    "\n",
    "Para seleccionar el número óptimo de clusters (`k`), usamos el **método del codo**:\n",
    "- Calculamos la **inercia** (suma de distancias de los puntos a sus centros de cluster) para diferentes valores de `k`.\n",
    "- La gráfica resultante nos permite identificar un “codo” donde el beneficio de añadir más clusters deja de ser significativo.\n",
    "\n",
    "Este punto suele indicar el número ideal de clusters a usar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSgPG286QcwO"
   },
   "source": [
    "Con el valor que hayáis obtenido de la gráfica, podéis obtener una buena aproximación de Kmeans y con ello podemos pasar a explorar cómo de bien han separado la información los distintos clusters. Para ello, se va a hacer un ``catplot``, seaborn os lo hará solito. Con esto lo que se pretende ver es la distribución de la varaible a predecir en función del cluster que haya determinado Kmeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wa7XfETyQcwO"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Asegurarse de tener los datos codificados y reducidos\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_encoded)\n",
    "\n",
    "# Definimos y entrenamos KMeans con k=2\n",
    "kmeans = KMeans(n_clusters=2, random_state=42, n_init='auto')\n",
    "clusters = kmeans.fit_predict(X_pca)\n",
    "\n",
    "# Creamos un nuevo DataFrame con la clase real y el cluster asignado\n",
    "df_clusters = pd.DataFrame({\n",
    "    \"class\": y.values,\n",
    "    \"cluster\": clusters\n",
    "})\n",
    "\n",
    "# Pintamos con catplot: distribución de clases dentro de cada cluster\n",
    "ax = sns.catplot(\n",
    "    col=\"cluster\",\n",
    "    x=\"class\",\n",
    "    data=df_clusters,\n",
    "    kind=\"count\",\n",
    "    col_wrap=2,\n",
    "    palette={\"e\": \"green\", \"p\": \"red\"}\n",
    ")\n",
    "ax.fig.suptitle(\"Distribución de clases reales por cluster (KMeans)\", y=1.05)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación visual de los clusters\n",
    "\n",
    "Aunque KMeans no usa la variable `class`, podemos comparar sus resultados con las etiquetas reales para ver si hay alguna relación.\n",
    "\n",
    "Usamos `sns.catplot` para representar la distribución de clases (`e` o `p`) dentro de cada cluster creado por KMeans.\n",
    "\n",
    "Esto nos permite evaluar si el algoritmo de clustering ha conseguido **separar razonablemente bien los hongos comestibles y venenosos** sin necesidad de entrenamiento supervisado.\n",
    "\n",
    "Si un cluster contiene mayoritariamente una sola clase, podemos considerar que la separación es significativa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzMUKFwzQcwO"
   },
   "source": [
    "Vamos a ver qué tal queda esto pintado. Para ello, repetimos el scatterplot de antes pero usando como color el cluster asignado por kmeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IjhjuexcQcwO"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Asegúrate de que X_encoded está disponible\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "# Reducimos a 2 componentes con PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_encoded)\n",
    "\n",
    "# Entrenamos KMeans (si no lo has hecho ya)\n",
    "kmeans = KMeans(n_clusters=2, random_state=42, n_init='auto')\n",
    "clusters = kmeans.fit_predict(X_pca)\n",
    "\n",
    "# Creamos un DataFrame para graficar\n",
    "df_pca_clusters = pd.DataFrame(X_pca, columns=[\"PC1\", \"PC2\"])\n",
    "df_pca_clusters[\"cluster\"] = clusters\n",
    "\n",
    "# Visualizamos los clusters en el espacio PCA\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(\n",
    "    x=\"PC1\", y=\"PC2\", hue=\"cluster\", palette=\"Set1\", data=df_pca_clusters, alpha=0.7\n",
    ")\n",
    "plt.title(\"Clusters obtenidos por KMeans en el espacio PCA\")\n",
    "plt.xlabel(\"Componente principal 1\")\n",
    "plt.ylabel(\"Componente principal 2\")\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de clusters en espacio PCA\n",
    "\n",
    "En este scatterplot proyectamos los datos en 2D usando PCA y coloreamos cada punto según el **cluster asignado por KMeans**.\n",
    "\n",
    "Esto nos permite ver gráficamente **cómo ha agrupado los datos el algoritmo de clustering**, sin necesidad de etiquetas.\n",
    "\n",
    "Si los clusters aparecen claramente separados, significa que **KMeans ha identificado patrones naturales en los datos**, incluso sin saber qué clase corresponde a cada punto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0q-ZDhQQcwO"
   },
   "source": [
    "¿Es bastante parecido no? No es tan bueno como el Random Forest, pero ha conseguido identificar bastante bien los distintos puntos del dataset sin utilizar las etiquetas. De hecho, el diagrama de factor que hemos visto antes muestra que solo un par de clusters son imprecisos. Si no hubieramos tenido etiquetas esta aproximacion nos hubiera ayudado mucho a clasificar los distintos tipos de hongos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ Conclusiones finales\n",
    "\n",
    "Al comparar los resultados de KMeans (no supervisado) con los de Random Forest (supervisado), observamos lo siguiente:\n",
    "\n",
    "- El **Random Forest** obtuvo una clasificación excelente, como era de esperar, ya que utiliza las etiquetas durante el entrenamiento.\n",
    "- El algoritmo **KMeans**, aunque no tiene acceso a las etiquetas (`class`), ha conseguido **agrupar correctamente la mayoría de los puntos** del dataset en dos clusters bien diferenciados.\n",
    "- El gráfico de `catplot` mostró que **solo algunos clusters tienen mezcla de clases**, pero en general la separación es bastante buena.\n",
    "- La visualización en el espacio PCA con colores por cluster confirma que los **datos tienen una estructura latente clara**, que puede ser aprovechada incluso sin supervisión.\n",
    "\n",
    "📌 **Si no hubiéramos tenido etiquetas**, esta aproximación basada en PCA + KMeans nos habría servido para **detectar dos grupos principales** en el dataset de hongos, lo cual ya ofrece un valor muy significativo en tareas de exploración y descubrimiento de patrones.\n",
    "\n",
    "En resumen:\n",
    "\n",
    "> Aunque el modelo no supervisado no alcanza la precisión del supervisado, ha demostrado ser una **herramienta útil y potente** para clasificar y entender datos complejos sin necesidad de etiquetas.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
